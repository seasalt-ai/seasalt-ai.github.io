const n=`---
title: "의도/개체 기반 NLU vs. GenAI/LLM 기반 NLU: 수백만 (예시 및 달러)의 차이"
metatitle: "의도/개체 기반 NLU vs. GenAI/LLM 기반 NLU"
date: 2024-03-14 00:22:19-07:00
modified_date: 2025-07-28T16:56:53Z
draft: false
author: Xuchen Yao
description: 대화형 AI의 미래를 열어보세요. 의도/개체 기반 NLU에서 GenAI/LLM 기반 NLU로의 전환이 확장성, 비용 효율성 및 적응성에 왜 중요한가요?"
weight: 1
tags:
  - SeaChat
  - AI Tools
  - Customer Experience
  - Customer Story
  - NLU
image: /images/blog/73-Intent-entity-based-NLU-vs-GenAI-LLM-based-NLU/73-Intent-entity-based-NLU-vs-GenAI-LLM-based-NLU.png
canonicalURL: /blog/intent-entity-based-nlu-vs-genai-llm-based-nlu/
url: /blog/intent-entity-based-nlu-vs-genai-llm-based-nlu/
---

모든 고객 서비스 또는 마케팅 이사님들께, 상사께서 다음 질문을 하시면 이 글을 보내주세요:

"**의도/개체 기반 NLU가 왜 구식이고 LLM/GenAI가 명백한 추세인가요?**"

자연어 이해(NLU) 시스템은 텍스트나 음성과 같은 자연어 입력을 처리하고 분석하여 의미를 도출하고 관련 정보를 추출하며 커뮤니케이션의 근본적인 의도를 이해하는 것을 목표로 합니다. NLU는 가상 비서, 챗봇, 감성 분석 도구, 언어 번역 시스템 등 다양한 AI 애플리케이션의 기본 구성 요소입니다. 이는 인간-컴퓨터 상호 작용을 가능하게 하고 자연어 입력을 이해하고 응답할 수 있는 지능형 시스템 개발을 촉진하는 데 중요한 역할을 합니다.

이 질문은 IVR 및 챗봇 접근 방식을 재고하고 있는 기존 고객으로부터 나옵니다. 이들은 [Microsoft Bot Framework](https://dev.botframework.com/) (또는 [luis.ai](https://luis.ai")), [IBM Watson NLU](https://www.ibm.com/products/natural-language-understanding), [Google DialogFlow](https://cloud.google.com/dialogflow), [Meta’s wit.ai](https://wit.ai), [Amazon Lex](https://aws.amazon.com/lex/), [SAP Conversational AI](https://cai.tools.sap/), [Nuance Mix NLU](https://www.nuance.com/omni-channel-customer-engagement/ai-for-developers/nuance-mix/mix-nlu.html)와 같은 대형 기술 기업들이 일반적으로 제공하는 이전 세대 NLU 기반 기술 스택에 갇혀 있습니다.

문제는 보험 회사, 금융 기관, 정부, 항공사/자동차 딜러십 및 기타 대규모 거래와 같은 주요 고객이 이미 최신 기술을 배포했다는 것입니다. 그러나 의도/개체 기반 NLU는 확장성이 없기 때문에 고객은 NLU 시스템을 유지 관리하고 업그레이드하는 데 매년 수십만에서 수백만 달러를 지출해야 합니다. 이러한 확장성 부족은 유지 관리 비용 증가에 기여하며, 궁극적으로 고객의 비용으로 이전 세대 NLU 공급업체에 이익을 줍니다. 확장성이 없기 때문에 유지 관리 비용은 매년 증가합니다.

## 의도/개체 기반 NLU가 효과적으로 확장되지 못하는 이유는 무엇인가요?

주요 원인은 모델의 제한된 식별 능력에 있습니다. 그 이유는 다음과 같습니다.

1. **최소 의도 요구 사항**: NLU 모델은 효과적으로 훈련하기 위해 최소 두 가지 고유한 의도를 필요로 합니다. 예를 들어, 날씨에 대해 물을 때 의도는 명확할 수 있지만, 각 쿼리 뒤에는 폴백 또는 "잘 지내세요?"와 같은 날씨와 관련 없는 문의와 같은 여러 잠재적 의도가 있습니다.

2. **훈련 데이터 요구 사항**: 대형 기술 기업은 일반적으로 효과적인 훈련을 위해 의도당 수천 개의 긍정적인 예시를 요구합니다. 이 광범위한 데이터 세트는 모델이 다양한 의도를 정확하게 학습하고 구별하는 데 필요합니다.

3. **긍정적 및 부정적 예시의 균형**: 한 의도에 긍정적 예시를 추가하려면 다른 의도에 대한 부정적 예시를 포함해야 합니다. 이 균형 잡힌 접근 방식은 NLU 모델이 긍정적 및 부정적 인스턴스 모두에서 효과적으로 학습할 수 있도록 보장합니다.

4. **다양한 예시 세트**: 과적합을 방지하고 모델이 다양한 컨텍스트에서 일반화하는 능력을 향상시키기 위해 긍정적 및 부정적 예시 모두 다양해야 합니다.

5. **새로운 의도 추가의 복잡성**: 기존 NLU 모델에 새로운 의도를 추가하는 것은 힘든 과정입니다. 수천 개의 긍정적 및 부정적 예시를 추가해야 하며, 그 후 모델의 기본 성능을 유지하기 위해 재훈련해야 합니다. 이 과정은 의도 수가 증가함에 따라 점점 더 어려워집니다.

## 처방 효과: 의도/개체 기반 NLU의 함정

<center>
<img height="100%" width="50%" src="/images/blog/73-Intent-entity-based-NLU-vs-GenAI-LLM-based-NLU/the-prescribing-effect-the-pitfall-of-Intent-entity-based-NLU-01.jpg" alt="의도/개체 기반 NLU의 처방 효과">

*의도/개체 기반 NLU의 처방 효과*
</center>


의학에서 "**처방 캐스케이드**"로 알려진 현상과 유사하게, 의도/개체 기반 NLU의 확장성 문제는 무시무시한 처방 캐스케이드에 비유될 수 있습니다. 매일 수많은 약을 복용해야 하는 노인을 상상해 보세요. 각 약은 이전 약의 부작용을 해결하기 위해 처방됩니다. 이 시나리오는 너무나 익숙합니다. 약 A의 도입이 부작용을 일으켜 약 B를 처방해야 하는 상황이 발생합니다. 그러나 약 B는 자체적인 부작용을 일으켜 약 C 등이 필요하게 됩니다. 결과적으로 노인은 관리해야 할 약 더미에 휩싸이게 됩니다. 이것이 바로 처방 캐스케이드입니다.

또 다른 비유는 블록으로 탑을 쌓는 것입니다. 각 블록은 약을 나타냅니다. 처음에는 약 A가 놓이지만, 그 불안정성(부작용)으로 인해 약 B를 추가하여 안정화해야 합니다. 그러나 이 새로운 추가는 원활하게 통합되지 않아 탑이 더 기울어질 수 있습니다(B의 부작용). 이 불안정성을 바로잡기 위해 더 많은 블록(약 C, D 등)이 추가되어 탑의 불안정성과 붕괴 가능성을 악화시킵니다. 이는 여러 약물로 인해 발생할 수 있는 잠재적인 건강 합병증을 나타냅니다.

<center>
<img height="60%" width="60%" src="/images/blog/73-Intent-entity-based-NLU-vs-GenAI-LLM-based-NLU/the-prescribing-effect-the-pitfall-of-Intent-entity-based-NLU-02.jpg" alt="의도/개체 기반 NLU에 대한 또 다른 비유는 블록으로 탑을 쌓는 것입니다.">

*의도/개체 기반 NLU에 대한 또 다른 비유는 블록으로 탑을 쌓는 것입니다.*
</center>

마찬가지로, NLU 시스템에 새로운 의도가 추가될 때마다 은유적인 블록 탑은 더 높아져 불안정성이 증가합니다. 강화의 필요성이 커지면서 유지 보수 비용이 높아집니다. 결과적으로 의도/개체 기반 NLU는 처음에는 공급업체에게 매력적으로 보일 수 있지만, 실제로는 고객이 유지 관리하기에 과도하게 부담스러워집니다. 이러한 시스템은 확장성이 부족하여 공급업체와 고객 모두에게 상당한 어려움을 초래합니다.
다음 섹션에서는 GenAI/LLM 기반 NLU가 이러한 문제를 효과적으로 해결하기 위한 보다 지속 가능하고 확장 가능한 대안을 어떻게 제공하는지 살펴보겠습니다.

## GenAI/LLM 기반 NLU: 탄력적인 솔루션

GenAI/LLM 기반 NLU는 의도/개체 기반 시스템이 직면한 확장성 문제에 대한 강력한 솔루션을 제공합니다. 이는 주로 두 가지 주요 요인에 기인합니다.

1. **사전 훈련 및 세계 지식**: GenAI/LLM 모델은 방대한 양의 데이터로 사전 훈련되어 풍부한 세계 지식을 상속받을 수 있습니다. 이 축적된 지식은 다양한 의도를 구별하는 데 중요한 역할을 하여 부정적인 예시에 대한 모델의 식별 능력을 향상시킵니다.

2. **Few-Shot 학습**: GenAI/LLM 기반 NLU의 특징 중 하나는 Few-Shot 학습 기술을 사용할 수 있다는 것입니다. 각 의도에 대해 광범위한 훈련 데이터가 필요한 기존 방법과 달리 Few-Shot 학습은 모델이 몇 가지 예시만으로 학습할 수 있도록 합니다. 이 효율적인 학습 접근 방식은 최소한의 데이터로 의도된 목표를 강화하여 훈련 부담을 크게 줄입니다.

이 시나리오를 고려해 보세요. 독자로서 "오늘 날씨는 어때요?"라는 질문을 받았을 때, 당신은 본능적으로 그것을 매일 접하는 수많은 문장들 속에서 날씨에 대한 질문으로 인식합니다. 의도를 구별하는 이러한 타고난 능력은 Few-Shot 학습의 개념과 유사합니다.

성인으로서 우리의 뇌는 방대한 어휘로 사전 훈련되어 있으며, 20세까지 약 1억 5천만 단어로 추정됩니다. 이러한 광범위한 언어 노출은 새로운 의도를 접했을 때 빠르게 이해할 수 있도록 해주며, 강화를 위해 몇 가지 예시만 필요합니다.

Urban Dictionary는 Few-Shot 학습의 실제 사례를 탐구하는 데 훌륭한 자료이며, 빠른 이해를 촉진하는 데 있어 그 효과를 더욱 잘 보여줍니다.

GenAI/LLM 기반 NLU에 내재된 Few-Shot 학습 기능은 비용 절감 및 확장성 구현에 필수적입니다. 사전 훈련 중에 대부분의 훈련이 이미 완료되었으므로, 최소한의 예시로 모델을 미세 조정하는 것이 주요 초점이 되어 프로세스를 간소화하고 확장성을 향상시킵니다.

## GenAI/LLM 기반 NLU: 결과 및 증거 제공

2024년 3월 현재, 자연어 처리(NLP) 분야는 GenAI/LLM 기반 NLU의 등장으로 큰 변화를 겪었습니다. 한때 지배적이었던 NLP 혁신의 진보는 최첨단 발전의 정체로 인해 지난 2-3년간 정체되었습니다. 한때 가장 인기 있었던 <a href="https://github.com/sebastianruder/NLP-progress">NLP 진행 상황</a>을 살펴보면, 대부분 2-3년 전에 멈췄습니다.

<center>
<img height="80%" width="80%" src="/images/blog/73-Intent-entity-based-NLU-vs-GenAI-LLM-based-NLU/nlp-progress.png" alt="이 Github Repo에서 NLP 혁신을 추적했습니다. 업데이트는 대부분 2-3년 전에 중단되었습니다.">

*이 Github Repo에서 NLP 혁신을 추적했습니다. 업데이트는 대부분 2-3년 전에 중단되었습니다.*
</center>

이러한 패러다임 전환을 강조하는 주목할 만한 벤치마크 중 하나는 2022년 12월에 마지막 항목이 추가된 <a href="https://super.gluebenchmark.com/leaderboard/">SuperGlue 리더보드</a>입니다. 흥미롭게도 이 시기는 ChatGPT(3.5)의 도입과 일치하며, 이는 NLP 커뮤니티에 큰 충격을 주었습니다.

<center>
<img height="80%" width="80%" src="/images/blog/73-Intent-entity-based-NLU-vs-GenAI-LLM-based-NLU/superglue-leaderboard.png" alt="SuperGlue 리더보드는 ChatGPT 도입 전까지 인기가 있었습니다.">

*SuperGlue 리더보드는 ChatGPT 도입 전까지 인기가 있었습니다.*
</center>

GPT-3의 중요한 논문인 "<a href="https://arxiv.org/abs/2005.14165">언어 모델은 Few-Shot 학습자이다</a>"는 Few-Shot 학습의 효과에 대한 설득력 있는 증거를 제공합니다. 논문 7페이지의 그림 2.1은 제로샷, 원샷, Few-Shot 학습 접근 방식 간의 차이점을 설명하며, 학습 효율성과 효과성 측면에서 후자의 우수성을 강조합니다.


<center>
<img height="80%" width="80%" src="/images/blog/73-Intent-entity-based-NLU-vs-GenAI-LLM-based-NLU/few-shot-learners.png" alt="제로샷, 원샷, Few-Shot 학습 접근 방식 간의 차이점">

*제로샷, 원샷, Few-Shot 학습 접근 방식 간의 차이점*
</center>

또한 GenAI/LLM 기반 NLU의 효과를 입증하는 것은 19페이지의 표 3.8입니다. 이 표는 전통적인 지도 학습 NLU 방법과 GPT-3 Few-Shot 학습 간의 직접적인 비교를 제공합니다. 이 비교에서 GPT-3 Few-Shot은 의도/개체 기반 NLU 시스템에서 사용되는 지도 학습의 대표인 Fine-tuned BERT-Large를 다양한 작업에서 능가합니다.

<center>
<img height="100%" width="100%" src="/images/blog/73-Intent-entity-based-NLU-vs-GenAI-LLM-based-NLU/gpt-performance.png"  alt="GPT-3 Few-Shot은 다양한 작업에서 Fine-tuned BERT-Large를 능가합니다.">

*GPT-3 Few-Shot은 다양한 작업에서 Fine-tuned BERT-Large를 능가합니다.*
</center>

GPT-3 Few-Shot의 우수성은 정확성뿐만 아니라 비용 효율성에서도 분명합니다. GenAI/LLM 기반 NLU와 관련된 초기 설정 및 유지 보수 비용은 기존 방법에 비해 훨씬 낮습니다.

NLP 커뮤니티에서 제시된 경험적 증거는 GenAI/LLM 기반 NLU의 혁신적인 영향을 강조합니다. 이미 탁월한 정확성과 효율성을 입증했습니다. 다음으로 비용 효율성을 살펴보겠습니다.

## 훈련 데이터 요구 사항: 비교 분석

의도/개체 기반 NLU와 GenAI/LLM 기반 NLU 간의 비교는 서로 다른 훈련 데이터 요구 사항을 명확히 보여줍니다. 20페이지의 그림 3.8은 극명한 대조를 보여줍니다.

<center>
<img height="100%" width="100%" src="/images/blog/73-Intent-entity-based-NLU-vs-GenAI-LLM-based-NLU/superglue-performance.png" alt="GenAI/LLM 기반 NLU는 훈련에 훨씬 적은 데이터를 필요로 합니다.">

*GenAI/LLM 기반 NLU는 훈련에 훨씬 적은 데이터를 필요로 합니다.*
</center>

- **지도 학습 NLU**: 이 전통적인 접근 방식은 효과적인 훈련을 위해 50만 개 이상의 예시(630K)가 필요한 광범위한 데이터 세트를 필요로 합니다.

- **Few-Shot GPT-3**: 대조적으로, GenAI/LLM 기반 NLU는 작업당 32개의 예시만으로도 효과적인 미세 조정에 충분하여 놀라운 효율성을 보여줍니다. 이 효율적인 학습 접근 방식은 최소한의 데이터로 의도된 목표를 강화하여 훈련 부담을 크게 줄입니다.

이러한 차이의 규모는 놀랍습니다. **630,000개의 예시 대 단 32개**. 훈련 데이터 요구 사항의 이러한 극적인 감소는 GenAI/LLM 기반 NLU를 채택하는 기업에 상당한 비용 절감 효과를 가져옵니다.

또한 개발 일정에 미치는 영향은 심오합니다. GenAI/LLM 기반 NLU를 사용하면 단축된 훈련 프로세스가 NLU 시스템 배포를 여러 배로 가속화하여 자연어 처리 분야에서 빠른 적응과 혁신을 촉진합니다.

본질적으로 이 비교는 GenAI/LLM 기반 NLU의 혁신적인 잠재력을 강조하며, 훈련 데이터 요구 사항 및 개발 일정에서 비할 데 없는 효율성과 비용 효율성을 제공합니다.

## 진화 수용: GenAI/LLM 기반 NLU가 우세한 이유


자연어 이해 분야에서 의도/개체 기반 시스템에서 GenAI/LLM 기반 솔루션으로의 전환은 논쟁의 여지 없이 진행 중입니다. 이러한 변화는 전통적인 의도/개체 기반 NLU의 한계와 GenAI/LLM 기반 접근 방식이 제공하는 설득력 있는 이점을 강조하는 다양한 요인에 의해 추진됩니다.

의도/개체 기반 NLU는 다음과 같은 몇 가지 설득력 있는 이유로 점점 더 구식으로 간주됩니다.

1. **제한된 유연성**: 전통적인 NLU 시스템은 미리 정의된 의도와 개체에 의존하므로, 미리 정의된 범주에서 벗어나는 사용자 입력에 대한 챗봇 및 IVR의 적응성이 제한됩니다.

2. **유지 보수 문제**: 이러한 시스템이 확장되고 의도 및 개체의 수가 증가함에 따라 유지 보수 및 업데이트에 필요한 복잡성과 시간이 기하급수적으로 증가합니다.

3. **상황 이해 부족**: 이러한 시스템은 대화의 복잡한 상황적 뉘앙스를 파악하는 데 종종 실패하여 부정확한 응답을 초래하거나 의도를 명확히 하기 위해 추가 사용자 입력이 필요합니다.

4. **생성 부족**: 의도 및 개체 기반 NLU 시스템은 텍스트 생성 능력에 본질적으로 제한되어 있으므로, 의도 분류 및 개체 추출에 중점을 둔 작업에 국한됩니다. 이는 챗봇 및 IVR의 적응성을 제한하여 대화 상황과 일치하지 않는 단조로운 응답으로 이어지는 경우가 많습니다.

이와는 대조적으로, GenAI/LLM 기반 NLU는 다음과 같은 혁신적인 특성으로 인해 지배적인 추세로 부상하고 있습니다.

1. **적응형 학습**: GenAI 모델은 실시간 대화에서 동적으로 학습할 수 있는 능력을 가지고 있어 수동 업데이트 없이도 새로운 주제와 사용자 행동에 자율적으로 적응할 수 있습니다.

2. **상황 이해**: 이 모델은 대화의 복잡한 상황적 뉘앙스를 이해하는 데 탁월하여 사용자에게 공감하는 더 정확하고 관련성 높은 응답을 생성합니다.

3. **Few-Shot 학습**: GenAI 모델은 최소한의 예시로 훈련할 수 있어 훈련 프로세스를 간소화하고 명시적인 의도 및 개체 정의에 대한 의존도를 줄입니다.

4. **자연어 생성**: GenAI/LLM은 텍스트를 생성할 수 있는 능력을 자랑하며, 자연스럽고 상황에 맞는 응답을 제공하는 챗봇 및 기타 NLP 애플리케이션을 만들 수 있습니다.

대화형 AI의 미래는 유기적으로 학습하고 적응할 수 있는 시스템에 달려 있으며, 사용자에게 원활하고 직관적인 경험을 제공합니다. GenAI/LLM 기반 NLU는 이러한 진화를 구현하며, 전통적인 의도/개체 기반 시스템의 제약을 뛰어넘는 동적이고 유연한 접근 방식을 제공합니다.

본질적으로 NLU의 지배적인 궤적은 GenAI/LLM 기반 접근 방식의 부상으로 명확하게 정의되며, 적응성, 상황성 및 사용자 중심성을 우선시하는 대화형 AI의 새로운 시대를 예고합니다.
`;export{n as default};

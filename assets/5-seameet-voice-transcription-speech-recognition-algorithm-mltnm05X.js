const e=`---
title: "От демо к успеху: За пределами алгоритмов распознавания речи современных встреч (3/5)"
metatitle: "От демо к успеху (3/5): За пределами алгоритмов речи"
date: 2021-07-30 17:43:38-07:00
modified_date: 2025-07-29 00:00:00+00:00
draft: false
author: Cody Kim, Shayne Mei
description: "В третьей части этой серии блогов следите за путешествием Seasalt.ai по созданию SeaMeet — нашего решения для современных совместных встреч."
weight: 1
tags:
  - SeaMeet
image: images/blog/3-implementing-Microsoft-modern-meetings-and-beyond/SeaMeet animation.gif
canonicalURL: /blog/seameet-voice-speech-recognition/
url: /blog/seameet-voice-speech-recognition/
---

*В этой серии блогов следите за путешествием Seasalt.ai по созданию полноценного опыта современных встреч: от скромного начала, оптимизации сервиса на разном оборудовании и моделях, интеграции передовых NLP-систем и, наконец, полной реализации SeaMeet — нашего решения для совместных встреч.*

## За пределами алгоритма
Modern Meetings был отличной демонстрацией, но так и остался демо. До готовности к производству еще далеко. Сначала мы успешно реализовали демо-версию с помощью Microsoft Azure stack. Но, осознав все недостатки ПО, мы решили заменить алгоритмы на свои собственные и сделать весь опыт более плавным, легким и гибким.
В Modern Meetings есть четыре основных компонента:

1. Обработка сигнала на микрофонной матрице, особенно beam forming
2. Диаризация и идентификация говорящих
3. Индивидуальное распознавание речи
4. Улучшенный пользовательский интерфейс

Далее подробно рассмотрим все важные компоненты.

<center>
<img src="/images/blog/5-seameet-voice-intelligence-meeting-transcription-speech-recognition-algorithm-of-modern-meeting/tech-stack.png" alt="SeaMeet architect with 4 major components"/>

*Мы адаптировали все 4 основных компонента Modern Meetings с помощью собственной технологии: 1. Обработка сигнала микрофонной матрицей; 2. Диаризация и идентификация говорящих; 3. Индивидуальное распознавание речи; 4. Современный веб-интерфейс.*
</center>

### Обработка сигнала на микрофонной матрице
Микрофонная матрица, по сравнению с одним микрофоном, расположенным близко ко рту, улавливает голоса со всех сторон на расстоянии до 5 метров. Таким образом, одна микрофонная матрица способна собирать голос в конференц-зале среднего размера 10x10 метров. Поскольку все микрофоны собраны в одном устройстве, это значительно уменьшает количество проводов в комнате и упрощает установку и обслуживание.
Цель использования микрофонной матрицы — предоставить нашим моделям максимально качественные данные. Поэтому перед автоматическим распознаванием речи мы сначала выполняем несколько алгоритмов обработки сигнала. Основной компонент нашего конвейера предварительной обработки — алгоритм beamforming. Поскольку мы работаем с круглыми многомикрофонными матрицами, мы можем использовать небольшую разницу во времени, которую требуется звуку, чтобы достичь разных микрофонов. Beamforming определяет основные характеристики сигнала — лучший луч — и усиливает эти частоты, одновременно ослабляя нежелательные звуки. Эффект — шумоподавление и устранение реверберации, а основной сигнал (речь) становится громче и четче.

Для оптимальной работы многих алгоритмов beamforming необходимо знать точное положение источника (говорящего) относительно микрофона. Но в реальном приложении это невозможно, поэтому сначала мы вычисляем так называемые веса дальнего поля, определяя направление источника. Этот первый шаг, известный как локализация источника или, точнее, Direction of Arrival (DOA), оказался сложным. Основная проблема — сглаживание. Алгоритм давал примерно правильный результат, но определенный источник постоянно колебался на 30 градусов в обе стороны от истинного направления, что мешало beamforming. Наше решение — позволить алгоритму локализации источника использовать только диапазон частот, кодирующих основную часть человеческой речи. Мы объединили это с техникой сглаживания, сохраняя «историю» результатов DOA для усреднения. С более надежными результатами DOA мы могли вычислить веса дальнего поля и использовать их для определения лучшего луча.

С помощью серии алгоритмов, выполненных на Kinect DK: beamforming, шумоподавление, устранение реверберации, локализация источника, мы смогли получать четкую и улучшенную человеческую речь в реальном времени, а также примерно определять направление говорящего. Это очень поможет в идентификации говорящего на следующем этапе.

### Диаризация и идентификация говорящих

Следующий компонент современной системы транскрипции встреч — автоматическое распознавание говорящих. Как было сказано в предыдущей части этой серии, читать неорганизованный текст разговора без информации о том, кто что сказал, — это раздражает и полностью лишает систему смысла. Здесь и пригодится распознавание говорящих.

С помощью этого компонента мы можем автоматически сопоставлять транскрипции и аудио с именем говорящего. Для этого мы используем процесс, называемый диаризацией, который группирует аудиосегменты в определенное количество групп, соответствующее количеству говорящих в записи. Это работает с помощью системы Voice Activity Detection (VAD) для определения речевых сегментов, из которых мы можем извлечь векторное представление короткого окна. Каждый вектор, извлеченный из окон, называется xvector уровня высказывания, а при усреднении мы получаем xvector уровня говорящего. Эти xvector затем проходят через алгоритм кластеризации, где каждый кластер представляет речевые сегменты, принадлежащие одному говорящему. Стоит отметить, что выбор алгоритма кластеризации сильно влияет на производительность диаризации, и мы достигли оптимального показателя Diarization Error Rate (DER) с помощью спектральной кластеризации, используя пороговую матрицу аффинности, автоматически настраиваемую с помощью значений Normalized Maximum Eigengap (NME). Наконец, нужно определить, какой говорящий соответствует каждому кластеру. Перед встречей можно провести процесс регистрации, чтобы извлечь xvector из 40-секундных записей каждого говорящего, которые можно сравнить с кластерами для идентификации соответствующего говорящего.

Гибкость этого конвейера — его главное достоинство. Во многих сценариях встреч невозможно заранее получить записи каждого говорящего. Например, деловые встречи с VIP-клиентами или крупные симпозиумы с 50 говорящими. В этом случае, пропуская этап регистрации, наша система диаризации все равно может разделить речевые сегменты и сгруппировать те, что принадлежат одному говорящему. Достаточно, чтобы человек прослушал несколько секунд из каждого кластера, чтобы определить личность говорящего. Вместе с современной пользовательской веб-интерфейсом мы можем предоставить ту же функциональность, но с большей гибкостью.

### Индивидуальное распознавание речи

Познакомившись с транскриптором встреч Microsoft и поняв его преимущества, мы были готовы сделать нашу систему полностью независимой и выйти за рамки уже революционного продукта. Движущая сила Modern Meetings и любого продукта транскрипции — это модели автоматического распознавания речи (ASR). Поэтому именно на них мы сосредоточили основное внимание.
Azure Cognitive Services предложил множество моделей для разных языков и диалектов. Однако различить производительность между диалектами было сложно. Для отдельных английских диалектов, вероятно, основное внимание и данные были уделены американской модели английского, которая затем была доработана с помощью акцентированных данных для создания различных диалектных моделей. Мы хотели убедиться, что если мы предлагаем отдельную модель, она настроена для конкретного случая использования. Это означало сбор тысяч часов локализованного аудио и транскрипций и недели обучения и доработки. Но было приятно видеть, как наши модели становятся лучше с каждым эпохом и выполняют обещанное.

Имея прочную базовую модель, следующим шагом было расширение удобства использования и возможности настройки. В каждой отрасли есть свой жаргон, что затрудняет моделям ASR различать эзотерическую лексику и ряд обычных, фонетически похожих слов.

Наш ответ — SeaVoice, который предоставляет централизованное место, где пользователи могут легко настраивать модели под свои конкретные нужды.
`;export{e as default};
